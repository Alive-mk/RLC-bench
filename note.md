**RLC-Bench: When to Retrieve and When to Read Long? A Quantitative Study of Accuracyâ€“Latencyâ€“Cost**

**RAG vs Long-Context: Practical Trade-offs on Multi-Hop QA**

**Context Budgeting for LLMs: Top-k Retrieval or Long-Context Packing?**

 è¿™ä¸ªé¡¹ç›®å°±æ˜¯ç”¨**åŒä¸€å¥—æ•°æ®**ï¼ŒæŠŠä¸¤ç§â€œæŠŠçŸ¥è¯†å–‚ç»™å¤§æ¨¡å‹â€çš„æ–¹æ³•â€”â€”**RAGï¼ˆæ£€ç´¢å¢å¼ºï¼‰å’Œé•¿ä¸Šä¸‹æ–‡ç›´å¡ï¼ˆLong-Contextï¼‰**â€”â€”æ”¾åˆ°åŒä¸€è·‘é“ä¸Šï¼Œ**é‡åŒ–æ¯”è¾ƒå®ƒä»¬çš„å‡†ç¡®ç‡ä¸è€—æ—¶**ï¼Œå¸®ä½ å†³å®šåœ¨ä½ çš„åœºæ™¯é‡Œè¯¥é€‰å“ªæ¡è·¯çº¿ã€‚

# åœ¨å¹²ä»€ä¹ˆï¼ˆWhatï¼‰

- ä»»åŠ¡ï¼šå¤šè·³é—®ç­”ï¼ˆHotpotQA å­é›†ï¼‰ã€‚
- ä¸¤ç§æ–¹æ³•ï¼š
  - **RAG**ï¼šå…ˆç”¨å‘é‡æ£€ç´¢æŒ‘å‡º **Top-K** æ®µè½ï¼Œå†æŠŠè¿™å‡ æ®µæ‹¼è¿›æç¤ºé‡Œé—®æ¨¡å‹ã€‚
  - **é•¿ä¸Šä¸‹æ–‡ï¼ˆLCï¼‰**ï¼šæŠŠèƒ½å¡çš„ç›¸å…³æ®µè½å°½é‡**ä¸€æ¬¡æ€§é•¿æ–‡æ‹¼æ¥**ç»™æ¨¡å‹ã€‚
- åº¦é‡ï¼šå¯¹æ¯é“é¢˜è®°å½• **EM/F1ï¼ˆå‡†ç¡®æ€§ï¼‰** å’Œ **æ¨ç†å»¶è¿Ÿï¼ˆmsï¼‰**ï¼Œæœ€åè¾“å‡ºæ±‡æ€»è¡¨ `summary.csv`ã€‚
- å¤ç°ï¼šå›ºå®šä¾èµ–ä¸è„šæœ¬ï¼›ç»“æœé€æ ·æœ¬è½ç›˜åˆ° `runs/<æ—¶é—´æˆ³>/*.jsonl`ã€‚

# ç›®çš„ï¼ˆWhyï¼‰

1. **åšå†³ç­–**ï¼šç»™å‡ºâ€œ**å‡†ç¡®ç‡â€”å»¶è¿Ÿï¼ˆâ€”æˆæœ¬ï¼‰**â€çš„é‡åŒ–æƒè¡¡ï¼ŒæŒ‡å¯¼ä½ åœ¨äº§å“/è®ºæ–‡é‡Œ**é€‰ RAG è¿˜æ˜¯ LC**ï¼Œæˆ–ä¸¤è€…æ··ç”¨çš„é˜ˆå€¼ã€‚
2. **æ‰“æ ·æœ¬**ï¼šä¸€å‘¨å†…æ‹¿åˆ°ç¬¬ä¸€å¼ åŸºå‡†è¡¨ï¼Œåç»­å¾ˆå®¹æ˜“æ‰©å±•åˆ°**æ›´çœŸå®çš„å…¨å±€æ–‡æ¡£åº“ã€æ›´å¤šæ•°æ®é›†**ï¼Œå½¢æˆè®ºæ–‡/æŠ¥å‘Šçš„å®éªŒéª¨æ¶ã€‚
3. **å·¥ç¨‹å¯è½åœ°**ï¼šä»£ç ä¸ Docker éƒ½ç»™äº†ï¼Œæ¢æ¨¡å‹/æ”¹å‚æ•°å³å¯åœ¨ä½ è‡ªå·±çš„çŸ¥è¯†åº“ä¸Šå¤è·‘ã€‚

# ä½ ä¼šæ‹¿åˆ°çš„äº§å‡ºï¼ˆOutputsï¼‰

- `summary.csv`ï¼šä¸¤è¡Œï¼ˆrag / lcï¼‰çš„ **EMã€F1ã€å¹³å‡å»¶è¿Ÿ**ï¼›
- `rag.jsonl` / `lc.jsonl`ï¼šé€æ ·æœ¬è®°å½•ï¼ˆé¢„æµ‹ã€é‡‘æ ‡ã€å»¶è¿Ÿã€ä¸Šä¸‹æ–‡é•¿åº¦ç­‰ï¼‰ï¼›
- ï¼ˆå¯é€‰ï¼‰æŠŠ `k=1/3/5`ã€`max_chars=6k/12k/24k` è·‘æˆ**æ›²çº¿**ï¼Œç›´è§‚çœ‹å‡ºâ€œå¤šæ‹¿ä¸Šä¸‹æ–‡â€å¸¦æ¥çš„æ”¶ç›Šä¸ä»£ä»·ã€‚

# è®¾è®¡å–èˆï¼ˆAssumptionsï¼‰

- å…¥é—¨ç‰ˆå…ˆåœ¨æ¯é¢˜è‡ªå¸¦å€™é€‰æ®µè½é‡Œæ£€ç´¢ï¼ˆ**é—­é›†**ã€æœ€ç¨³ï¼‰ï¼Œæ–¹ä¾¿ä½ å…ˆè·‘é€šï¼›
- ä¸‹ä¸€æ­¥å¯æ‰©å±•åˆ°**å…¨å±€ç´¢å¼•ï¼ˆå¦‚ Wikipedia/ä¼ä¸šæ–‡æ¡£ï¼‰**ï¼Œæ›´è´´è¿‘çœŸå®æ£€ç´¢åœºæ™¯ï¼›
- æˆæœ¬ç»Ÿè®¡ï¼ˆtokensï¼‰ç•™ä½œåŠ åˆ†é¡¹ï¼Œä¾¿äºæŠŠç»“æœè½¬åŒ–ä¸º**è´¹ç”¨è¯„ä¼°**ã€‚

# æˆåŠŸæ ‡å‡†ï¼ˆDefinition of Doneï¼‰

- è·‘å®Œ 100 æ¡æ ·æœ¬ï¼Œå¾—åˆ°ä¸€å¼ è¡¨ï¼›é€šå¸¸ä¼šçœ‹åˆ°ï¼š
  - **LC** â†’ å¯èƒ½ç•¥é«˜çš„ EM/F1ï¼Œä½†**å»¶è¿Ÿæ›´é«˜**ï¼›
  - **RAG** â†’ å»¶è¿Ÿæ›´ä½ï¼Œå¯¹ **k** è¾ƒæ•æ„Ÿã€‚
- èƒ½æ®æ­¤ç»™å‡ºä¸€å¥**é€‰æ‹©å»ºè®®**ï¼ˆä¾‹å¦‚ï¼šâ€œæˆ‘ä»¬é¢†åŸŸé‡Œï¼Œk=3 çš„ RAG å·²ç»æ¥è¿‘ LCï¼Œä½†é€Ÿåº¦å¿« 40%+â€ï¼‰ã€‚

å¦‚æœä½  okï¼Œæˆ‘ä»¬ä¸‹ä¸€æ­¥å°±æŒ‰è¿™ç›®æ ‡è·‘â€œç¬¬ä¸€è½® 100 æ¡â€ï¼Œæˆ‘å†æ•™ä½ æŠŠç»“æœç”»æˆä¸€å¼ å¯¹æ¯”å›¾ï¼Œé¡ºä¾¿åšä¸¤ç‚¹å°æ¶ˆèï¼ˆk ä¸ max_charsï¼‰ã€‚

------

```
# 1) æ–°å»ºç¯å¢ƒï¼ˆPython 3.11ï¼‰
conda create -n rlc-bench python=3.11 -y
conda activate rlc-bench
python -m pip install -U pip

# 2) å®‰è£…ä¾èµ–ï¼ˆåœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰
pip install -r requirements.txt

# 3) è¿è¡Œ
# è®¾ç½® Keyï¼ˆæ›¿æ¢æˆä½ è‡ªå·±çš„ï¼‰
export OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxx" 

# å¦‚æœç”¨çš„æ˜¯å®˜æ–¹ OpenAIï¼Œä¸ç”¨è®¾ç½® baseï¼Œè„šæœ¬ä¼šé»˜è®¤èµ° https://api.openai.com/v1
# å¦‚æœä½ ç”¨çš„æ˜¯å…¼å®¹ç«¯ç‚¹ï¼ˆæ¯”å¦‚ä½ ä»¬çš„æœåŠ¡å™¨/ä»£ç†ï¼‰ï¼Œå°±è¦è®¾ï¼š
export OPENAI_BASE_URL="https://ä½ çš„åŸŸå/v1"

# å¯é€‰ï¼šæŒ‡å®šæ¨¡å‹å
export OPENAI_MODEL="gpt-4o-mini"
```

```
echo '' >> ~/.bashrc
echo '# >>> OpenAI API config >>>' >> ~/.bashrc
echo 'export OPENAI_API_KEY="sk-feQaMdPuRBDsZg3I667f359cAb7042B98246724b794e6c0c"' >> ~/.bashrc
echo 'export OPENAI_BASE_URL="https://api.ai-gaochao.cn/v1"' >> ~/.bashrc
echo 'export OPENAI_MODEL="gpt-4o-mini"' >> ~/.bashrc
echo '# <<< OpenAI API config <<<' >> ~/.bashrc

source ~/.bashrc

```

```
è„šæœ¬
#!/bin/bash
# ç”¨æ³•: ./setup_openai.sh sk-ä½ çš„key https://ä½ çš„base/v1 gpt-4o-mini

API_KEY=$1
BASE_URL=$2
MODEL=${3:-gpt-4o-mini}   # å¦‚æœæ²¡ä¼ ç¬¬ä¸‰ä¸ªå‚æ•°ï¼Œé»˜è®¤ gpt-4o-mini

if [ -z "$API_KEY" ]; then
  echo "âŒ è¯·ä¼ å…¥ API Keyï¼Œä¾‹å¦‚:"
  echo "   ./setup_openai.sh sk-xxxx https://api.openai.com/v1"
  exit 1
fi

# è¿½åŠ åˆ° ~/.bashrc
{
  echo ""
  echo "# >>> OpenAI API config >>>"
  echo "export OPENAI_API_KEY=\"$API_KEY\""
  if [ -n "$BASE_URL" ]; then
    echo "export OPENAI_BASE_URL=\"$BASE_URL\""
  fi
  echo "export OPENAI_MODEL=\"$MODEL\""
  echo "# <<< OpenAI API config <<<"
} >> ~/.bashrc

# è®©é…ç½®ç«‹å³ç”Ÿæ•ˆ
source ~/.bashrc

echo "âœ… å·²å†™å…¥ ~/.bashrc å¹¶ç”Ÿæ•ˆ"
echo "   OPENAI_API_KEY=${API_KEY:0:8}..."
echo "   OPENAI_BASE_URL=${BASE_URL:-é»˜è®¤ https://api.openai.com/v1}"
echo "   OPENAI_MODEL=$MODEL"


nano setup_openai.sh
# ç²˜è´´ä¸Šé¢çš„å†…å®¹ï¼Œä¿å­˜é€€å‡º
chmod +x setup_openai.sh

./setup_openai.sh sk-feQaMdPuRBDsZg3I667f359cAb7042B98246724b794e6c0c https://api.ai-gaochao.cn/v1 gpt-4o-mini

éªŒè¯
echo $OPENAI_API_KEY
echo $OPENAI_BASE_URL
echo $OPENAI_MODEL
```

<img src="../../AppData/Roaming/Typora/typora-user-images/image-20250827115543519.png" alt="image-20250827115543519" style="zoom:67%;" />

```
ä½ è¿™ä¸ªç•Œé¢æ˜¯ Vim çš„ E325 æŠ¥é”™ï¼Œæ„æ€æ˜¯ï¼š

ğŸ‘‰ Vim å‘ç°ä½ è¦æ‰“å¼€çš„æ–‡ä»¶ ~/.bashrc å·²ç»æœ‰ä¸€ä¸ª**äº¤æ¢æ–‡ä»¶ï¼ˆswap fileï¼‰**å­˜åœ¨ï¼š

~/.bashrc.swp

è¿™é€šå¸¸è¡¨ç¤ºï¼š

ä½ ä¹‹å‰åœ¨ Vim é‡Œæ‰“å¼€è¿‡è¿™ä¸ªæ–‡ä»¶ï¼Œä½†æ²¡æ­£å¸¸é€€å‡ºï¼ˆæ¯”å¦‚ç›´æ¥å…³äº†ç»ˆç«¯ï¼‰ã€‚

æˆ–è€…è¿™ä¸ªæ–‡ä»¶æ­¤åˆ»æ­£åœ¨è¢«å¦ä¸€ä¸ª Vim å®ä¾‹ç¼–è¾‘ã€‚

(O)pen Read-Only â†’ åªè¯»æ–¹å¼æ‰“å¼€ï¼Œä¸å…è®¸ä¿å­˜ã€‚

(E)dit anyway â†’ å¼ºè¡Œç¼–è¾‘ï¼Œå¿½ç•¥é‚£ä¸ª .swp æ–‡ä»¶ã€‚

(R)ecover â†’ å°è¯•ç”¨ .swp æ–‡ä»¶é‡Œçš„å†…å®¹æ¢å¤æœªä¿å­˜çš„ä¿®æ”¹ã€‚

(Q)uit â†’ ä»€ä¹ˆä¹Ÿä¸åšï¼Œç›´æ¥é€€å‡ºã€‚

(A)bort â†’ ä¸­æ­¢å¯åŠ¨ã€‚

å¸¸è§å¤„ç†æ–¹å¼

å¦‚æœä½ ç¡®å®šåªæ˜¯ä¸Šæ¬¡æ²¡é€€å‡ºå¹²å‡€ï¼ˆæ²¡æœ‰åˆ«çš„ Vim åœ¨ç¼–è¾‘ ~/.bashrcï¼‰ï¼š
ğŸ‘‰ æŒ‰ E å°±è¡Œï¼ˆEdit anywayï¼‰ã€‚
ç„¶åä¿å­˜æ—¶ä¼šè¦†ç›– .swp é‡Œçš„æ—§ä¸œè¥¿ã€‚
ä¿å­˜é€€å‡ºåå†æ‰§è¡Œï¼š

rm ~/.bashrc.swp


æŠŠå¤šä½™çš„äº¤æ¢æ–‡ä»¶åˆ æ‰ï¼Œä»¥åå°±ä¸ä¼šå†å¼¹äº†ã€‚

å¦‚æœä½ æƒ³çœ‹çœ‹ .swp é‡Œæ˜¯ä¸æ˜¯æœ‰æ²¡ä¿å­˜çš„ä¿®æ”¹ï¼š
ğŸ‘‰ æŒ‰ Rï¼ˆRecoverï¼‰ã€‚
Vim ä¼šç”¨ .swp é‡Œçš„å†…å®¹æ¢å¤æ–‡ä»¶ã€‚
ç„¶åå†æ‰‹åŠ¨ä¿å­˜ä¸€æ¬¡ï¼ˆ:wqï¼‰ï¼Œå†åˆ æ‰ .swp æ–‡ä»¶ã€‚
```

```
è¿è¡Œ RAG æ¨¡å¼ï¼š

python rag_vs_lc.py --method rag --limit 100 --k 3


è¿è¡Œ é•¿ä¸Šä¸‹æ–‡ æ¨¡å¼ï¼š

python rag_vs_lc.py --method lc --limit 100 --max_chars 12000
```

![image-20250829110255626](../../AppData/Roaming/Typora/typora-user-images/image-20250829110255626.png)

`AttributeError: _ARRAY_API not found` / `ImportError: numpy.core.multiarray failed to import` å‡ºåœ¨ **faiss**ï¼Œè¿™æ˜¯ **FAISS å’Œ NumPy çš„äºŒè¿›åˆ¶ä¸åŒ¹é…**ï¼ˆå¸¸è§äºåœ¨ conda é‡Œç”¨ pip è£…äº† faiss-cpuï¼ŒNumPy ç‰ˆæœ¬ä¸åŒæ­¥ï¼‰ã€‚

```
# å¸è½½ pip ç‰ˆ faissï¼Œé¿å…å†²çª
pip uninstall -y faiss-cpu faiss

# ç”¨ conda-forge å®‰è£…ï¼ˆä¼šè‡ªåŠ¨é…å¥½ä¾èµ–ï¼‰
conda install -y -c conda-forge faiss-cpu=1.8.* numpy=1.26.*

python - <<'PY'
import numpy, faiss, numpy as np
print("numpy:", numpy.__version__)
print("faiss:", faiss.__version__)
x = np.random.rand(5,4).astype('float32'); x/=np.linalg.norm(x,axis=1,keepdims=True)
index = faiss.IndexFlatIP(4); index.add(x); D,I = index.search(x[:1], 3)
print("ok:", D.shape, I.shape)
PY
```

```
ç¯å¢ƒé‡è£…

# é€€å‡ºåˆ°(base)ï¼Œå¤šæ•²å‡ æ¬¡ç›´åˆ°ä¸å†æ˜¾ç¤º (rlc-bench)
conda deactivate

# åˆ é™¤æ—§ç¯å¢ƒï¼ˆåå­—æŒ‰ä½ ç°åœ¨ç”¨çš„æ¥ï¼Œè¿™é‡Œæ˜¯ rlc-benchï¼‰
conda remove -n rlc-bench --all -y

conda env list    # ç¡®è®¤ rlc-bench ä¸åœ¨åˆ—è¡¨é‡Œäº†

# ç”¨ conda-forge åˆ›å»ºæ–°ç¯å¢ƒå¹¶ä¸€æ¬¡è£…é½æ ¸å¿ƒç§‘å­¦è®¡ç®—æ ˆ
conda create -n rlc-bench -c conda-forge -y \
  python=3.11 \
  numpy=1.26.4 scipy=1.11.4 scikit-learn=1.3.2 faiss-cpu=1.8.0 \
  pandas=2.1.4 pyarrow=14.0.2

conda activate rlc-bench
conda config --env --set channel_priority strict   # æœ¬ç¯å¢ƒå¯ç”¨ä¸¥æ ¼ä¼˜å…ˆçº§
python -m pip install -U pip


# ç¡®ä¿ requirements.txt åªæœ‰ä»¥ä¸‹å†…å®¹ï¼ˆä¸è¦æœ‰ numpy/scipy/sklearn/faiss/pandas/pyarrowï¼‰
# datasets
# sentence-transformers
# openai>=1.0.0
# tqdm
# PyYAML
# regex

python -m pip install -r requirements.txt

è‡ªæ£€
python - <<'PY'
import numpy as np, scipy, sklearn, faiss, pandas, pyarrow
from sentence_transformers import SentenceTransformer
from sklearn.metrics import pairwise_distances

print("numpy:", np.__version__, "scipy:", scipy.__version__,
      "sklearn:", sklearn.__version__, "faiss:", faiss.__version__)
m = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
emb = m.encode(["hello","world"], normalize_embeddings=True)
index = faiss.IndexFlatIP(emb.shape[1]); index.add(emb.astype("float32"))
print("pairwise:", pairwise_distances([[0,1],[1,0]]).shape, "faiss search:", index.search(emb[:1].astype("float32"), 2)[1])
PY

èƒ½æ‰“å°å‡ºç‰ˆæœ¬ã€pairwise: (2, 2) å’Œ faiss search: [[0 1]] ä¹‹ç±»å°± OKã€‚

å¦‚ä»æç¤º â€œNo module named numpyâ€ï¼šè¦ä¹ˆç¯å¢ƒæ²¡æ¿€æ´»ï¼Œè¦ä¹ˆ VS Code ç»ˆç«¯æ²¡æ¥ç®¡ condaã€‚

å…ˆ conda activate rlc-bench && which python çœ‹è·¯å¾„æ˜¯å¦åœ¨ â€¦/envs/rlc-bench/â€¦ã€‚

å¦‚æœ VS Code å†…ç½®ç»ˆç«¯ä¸ç”Ÿæ•ˆï¼šconda init bash åé‡å¼€ç»ˆç«¯ï¼›æˆ–ç”¨
conda run -n rlc-bench python rag_vs_lc.py --method rag --limit 100 --k 3
```

![image-20250830104256973](../../AppData/Roaming/Typora/typora-user-images/image-20250830104256973.png)

```
ä½ è¿™æ¡æŠ¥é”™æ˜¯ Conda åœ¨æ ¡éªŒä¸‹è½½åŒ…æ—¶å‘ç°ç¼“å­˜é‡Œçš„åŒ…æŸåäº†ï¼š

CondaVerificationError: The package for _openmp_mutex ... appears to be corrupted.
The path 'lib/libgomp.so.1' specified in the package manifest cannot be found.


æ„æ€ï¼š~/miniconda3/pkgs/_openmp_mutex-4.5-2_gnu è¿™ä¸ªåŒ…åœ¨æœ¬åœ°ç¼“å­˜ä¸å®Œæ•´ï¼ˆå°‘äº† lib/libgomp.so.1ï¼‰ï¼Œå¯¼è‡´åˆ›å»ºç¯å¢ƒå¤±è´¥ã€‚å¤„ç†åŠæ³•å°±æ˜¯æ¸…æ‰åç¼“å­˜â†’é‡æ–°ä¸‹è½½ã€‚æŒ‰ä¸‹é¢ä¸€æ­¥æ­¥åšï¼š

# é€€å‡ºåˆ° base ç¯å¢ƒ
conda deactivate

# åˆ æ‰æŸåçš„åŒ…ç¼“å­˜ï¼ˆç²¾ç¡®åˆ é™¤è¿™ç±»ç›®å½•/å‹ç¼©åŒ…ï¼‰
rm -rf ~/miniconda3/pkgs/_openmp_mutex-4.5-2_gnu*

# æ¸…ç†ç´¢å¼•ã€tarballã€å·²ä¸‹è½½ä½†æœªç”¨çš„åŒ…
conda clean --index-cache --tarballs --packages -y
# æˆ–è€…ä¸€æŠŠæ¢­ï¼šconda clean -a -y

conda update -n base -c conda-forge conda -y
conda install -n base -c conda-forge conda-libmamba-solver -y
conda config --set solver libmamba

```

------

![image-20250830113259457](../../AppData/Roaming/Typora/typora-user-images/image-20250830113259457.png)

```
method,limit,avg_em,avg_f1,avg_latency_ms,k_or_maxchars
lc,100,0.0000,0.0001,628.6,12000
method,limit,avg_em,avg_f1,avg_latency_ms,k_or_maxchars
rag,100,0.0000,0.0001,648.0,3


ä½ è¿™ä¸¤è¡Œæ˜¯ä¸¤æ¬¡è·‘å‡ºæ¥çš„æ±‡æ€»ï¼š

lc,100,0.0000,0.0001,628.6,12000   # é•¿ä¸Šä¸‹æ–‡ï¼šè·‘äº†100æ¡ï¼ŒEMâ‰ˆ0ï¼ŒF1â‰ˆ0.0001ï¼Œå¹³å‡å»¶è¿Ÿâ‰ˆ629msï¼Œä¸Šä¸‹æ–‡ä¸Šé™12000å­—ç¬¦
rag,100,0.0000,0.0001,648.0,3      # RAGï¼šè·‘äº†100æ¡ï¼ŒEMâ‰ˆ0ï¼ŒF1â‰ˆ0.0001ï¼Œå¹³å‡å»¶è¿Ÿâ‰ˆ648msï¼Œtop-k=3


æ„æ€ï¼šæ¨¡å‹ç»™å‡ºçš„ç­”æ¡ˆå‡ ä¹éƒ½æ²¡åŒ¹é…åˆ°æ ‡å‡†ç­”æ¡ˆï¼ˆè¦ä¹ˆç­”é”™ã€ç­”æ•´å¥ã€è¦ä¹ˆå¤§é‡è¾“å‡º unknownï¼‰ã€‚å»¶è¿Ÿ 0.6s ä¹Ÿå¼‚å¸¸å¿«ï¼Œåƒæ˜¯åœ¨è¿…é€Ÿè¿”å›å›ºå®šæ ·å¼ï¼ˆä¾‹å¦‚ä¸€ç›´ unknownï¼‰ã€‚
```

çœ‹çœ‹æ¨¡å‹åˆ°åº•å›ç­”äº†å•¥ï¼ˆunknown æ¯”ä¾‹ä¸æ ·ä¾‹ï¼‰

```
# RAG ç»“æœæŠ½æ ·+unknownå æ¯”
python - <<'PY'
import json,glob,random
p=sorted(glob.glob('runs/*/rag.jsonl'))[-1]
L=[json.loads(x) for x in open(p,encoding='utf-8')]
u=sum(1 for d in L if d["pred"].strip().lower().startswith("unknown"))
print(f"RAG unknownæ¯”ä¾‹: {u}/{len(L)} = {u/len(L):.1%}")
for d in random.sample(L,3):
    print("\nQ:",d["question"]);print("PRED:",d["pred"]);print("GOLD:",d["gold"])
PY

# LC åŒæ ·çœ‹ä¸€ä¸‹
python - <<'PY'
import json,glob,random
p=sorted(glob.glob('runs/*/lc.jsonl'))[-1]
L=[json.loads(x) for x in open(p,encoding='utf-8')]
u=sum(1 for d in L if d["pred"].strip().lower().startswith("unknown"))
print(f"LC unknownæ¯”ä¾‹: {u}/{len(L)} = {u/len(L):.1%}")
for d in random.sample(L,3):
    print("\nQ:",d["question"]);print("PRED:",d["pred"]);print("GOLD:",d["gold"])
PY

ç¡®è®¤æˆ‘ä»¬ç¡®å®æŠŠâ€œä¸Šä¸‹æ–‡â€å¡è¿›å»äº†ï¼ˆä¸æ˜¯ç©ºçš„ï¼‰

python - <<'PY'
import json,glob
p=sorted(glob.glob('runs/*/rag.jsonl'))[-1]
L=[json.loads(x) for x in open(p,encoding='utf-8')]
zero_ctx=sum(1 for d in L if d["ctx_chars"]==0 or d["num_ctx"]==0)
print(f"RAG ç©ºä¸Šä¸‹æ–‡æ ·æœ¬: {zero_ctx}/{len(L)}")
print("RAG å¹³å‡ctxé•¿åº¦:", sum(d["ctx_chars"] for d in L)//len(L))

p=sorted(glob.glob('runs/*/lc.jsonl'))[-1]
L=[json.loads(x) for x in open(p,encoding='utf-8')]
zero_ctx=sum(1 for d in L if d["ctx_chars"]==0 or d["num_ctx"]==0)
print(f"LC  ç©ºä¸Šä¸‹æ–‡æ ·æœ¬: {zero_ctx}/{len(L)}")
print("LC  å¹³å‡ctxé•¿åº¦:", sum(d["ctx_chars"] for d in L)//len(L))
PY

å¿«é€ŸéªŒè¯æ¥å£çœŸçš„åœ¨èµ° OpenAI å…¼å®¹ JSONï¼ˆä¸æ˜¯ 404/HTMLï¼‰

curl -sS -H "Authorization: Bearer $OPENAI_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{"model":"'"${OPENAI_MODEL:-gpt-4o-mini}"'","messages":[{"role":"user","content":"Say OK only."}]}' \
     "$OPENAI_BASE_URL/chat/completions" | head -n 3
æœŸå¾…æ˜¯ JSONï¼ˆä»¥ { å¼€å¤´ï¼‰ï¼›

å¦‚æœçœ‹åˆ° <html> æˆ– 404ï¼ŒOPENAI_BASE_URL è¿˜ä¸å¯¹ï¼Œå¿…é¡»ç”¨å¸¦ /v1 çš„çœŸæ­£æ¥å£ï¼ˆä¾‹å¦‚ https://.../v1ï¼‰ã€‚
```

![image-20250831105256403](../../AppData/Roaming/Typora/typora-user-images/image-20250831105256403.png)

è¿™æ˜¯åœ¨å‘Šè¯‰ä½ ï¼š**æ¨¡å‹è¿”å›çš„ä¸æ˜¯ç­”æ¡ˆï¼Œè€Œæ˜¯ä¸€æ•´é¡µç½‘ç«™çš„ 404 HTML**ã€‚
 é¡µé¢é‡Œæœ‰ â€œ`<div class="title">404</div>` / `Powered by aapanel`â€ï¼Œè¯´æ˜ä½ çš„è¯·æ±‚æ‰“åˆ°äº†ä¸€ä¸ªæ™®é€šç½‘ç«™ï¼ˆæˆ–é¢æ¿ï¼‰è€Œä¸æ˜¯ OpenAI å…¼å®¹çš„ APIã€‚

æœ€å¸¸è§åŸå› ï¼š**`OPENAI_BASE_URL` å†™é”™äº†ï¼Œå°‘äº† `/v1`**ã€‚

![image-20250831110053482](../../AppData/Roaming/Typora/typora-user-images/image-20250831110053482.png)

```
conda activate rlc-bench
conda install -y -c conda-forge libstdcxx-ng=13.2.0 libgcc-ng=13.2.0 _openmp_mutex=4.5=2_gnu
#ï¼ˆå·²ç»æœ‰ä¹Ÿæ— å¦¨ï¼Œå¼ºåˆ¶å¯¹é½åˆ° 13.xï¼‰

export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"

# æŒä¹…åŒ–ï¼ˆä»¥åæ¿€æ´»ç¯å¢ƒè‡ªåŠ¨ç”Ÿæ•ˆï¼‰
mkdir -p "$CONDA_PREFIX/etc/conda/activate.d"
printf 'export LD_LIBRARY_PATH="$CONDA_PREFIX/lib:$LD_LIBRARY_PATH"\n' \
  > "$CONDA_PREFIX/etc/conda/activate.d/zzz_ld_path.sh"

strings "$CONDA_PREFIX/lib/libstdc++.so.6" | grep GLIBCXX_3.4.30 || echo "missing"

```

:hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs:

![image-20250904094320169](../../AppData/Roaming/Typora/typora-user-images/image-20250904094320169.png)

**RAG (k=3)**ï¼šEM=**0.26**ï¼ŒF1=**0.366**ï¼Œå¹³å‡å»¶è¿Ÿâ‰ˆ**1498 ms**

**é•¿ä¸Šä¸‹æ–‡ LC (12k chars)**ï¼šEM=**0.35**ï¼ŒF1=**0.489**ï¼Œå¹³å‡å»¶è¿Ÿâ‰ˆ**1561 ms**

**å‡†ç¡®ç‡**ï¼šLC æ¯” RAG **é«˜ ~0.09 EM / ~0.12 F1**ï¼Œè¯´æ˜ *k=3 çš„ RAG å¬å›ä»ä¼šæ¼å…³é”®ä¿¡æ¯*ï¼›LC ä¸€æ¬¡æ€§å–‚æ›´å¤šåŸæ–‡ï¼Œæ¼æ‰çš„å°‘ã€‚

**æ—¶å»¶**ï¼šLC åªæ¯” RAG **æ…¢ ~62 msï¼ˆâ‰ˆ4%ï¼‰**ï¼Œå·®è·å¾ˆå°ï¼ˆåœ¨ä½ è¿™ä¸ªæ¨¡å‹å’Œé•¿åº¦ä¸Šï¼Œé•¿ä¸Šä¸‹æ–‡çš„é¢å¤–å¼€é”€ä¸å¤§ï¼‰ã€‚

ç²—ç»“è®ºï¼š**è‹¥æ›´çœ‹é‡å‡†ç¡®ï¼ŒLC æ›´æœ‰ä¼˜åŠ¿ï¼›è‹¥è¿½æ±‚åå/æˆæœ¬ï¼ŒRAG éœ€è¦æŠŠ k æ‹‰é«˜æ¥â€œè¿½ä¸Šâ€å‡†ç¡®åº¦**

:hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs:

æŠŠ RAG çš„å¬å›æ‹‰æ»¡ä¸€ç‚¹ã€LC å†è¯•æ›´é•¿ä¸Šé™â€”â€”çœ‹çœ‹èƒ½å¦é€¼è¿‘/æ‹‰å¼€å·®è·ï¼š

```
# RAGï¼šk ç½‘æ ¼
python rag_vs_lc.py --method rag --limit 100 --k 5 --temperature 0.0
python rag_vs_lc.py --method rag --limit 100 --k 7 --temperature 0.0

# LCï¼šæ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼ˆæ¨¡å‹å…è®¸çš„è¯ï¼‰
python rag_vs_lc.py --method lc  --limit 100 --max_chars 20000 --temperature 0.0
```

![image-20250904102544661](../../AppData/Roaming/Typora/typora-user-images/image-20250904102544661.png)

- **RAG (k=5)**ï¼šEM=**0.27**ï¼ŒF1=**0.377**ï¼ŒLatencyâ‰ˆ**1544 ms**
- **RAG (k=7)**ï¼šEM=**0.27**ï¼ŒF1=**0.404**ï¼ŒLatencyâ‰ˆ**1527 ms**
- **LC (max_chars=20k)**ï¼šEM=**0.33**ï¼ŒF1=**0.479**ï¼ŒLatencyâ‰ˆ**1471 ms**

1. **å‡†ç¡®ç‡**ï¼šLC ä»ç„¶é¢†å…ˆï¼ˆF1 é«˜ ~0.07â€“0.10ï¼‰ã€‚RAG æŠŠ k ä» 5 â†’ 7 å**æœ‰æå‡**ï¼ˆF1 +0.027ï¼‰ï¼Œä½† EM æ²¡å†æ¶¨ï¼Œè¯´æ˜**å¬å›æé«˜äº†ä½†ç­”æ¡ˆæŠ½å–ä»æœ‰miss**ã€‚
2. **æ—¶å»¶**ï¼šä¸‰è€…éƒ½åœ¨ ~1.5s å·¦å³ï¼Œ**å·®è·å¾ˆå°**ï¼›ä½ çš„ç«¯ç‚¹ä¸‹ï¼ŒLC çš„é¢å¤–å¼€é”€ä¸æ˜æ˜¾ã€‚
3. **20k é•¿ä¸Šä¸‹æ–‡æœªèƒœè¿‡ 12k**ï¼šå‡ºç°â€œè¾¹é™…æ”¶ç›Šé€’å‡/å¯èƒ½è¢«æˆªæ–­â€ã€‚è¯´æ˜ç»§ç»­åŠ é•¿ä¸Šä¸‹æ–‡ä¸ä¸€å®šæ›´å‡†ï¼›åº”æ§åˆ¶åœ¨æ¨¡å‹ token ä¸Šé™å†…ï¼Œå¹¶ä¼˜å…ˆæé«˜ä¿¡æ¯å¯†åº¦ï¼ˆæ›´å¥½çš„æ£€ç´¢/æ’åºï¼‰ã€‚

:hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs:

```
# RAG ç½‘æ ¼ï¼ˆçœ‹æ˜¯å¦ç»§ç»­æ¶¨ï¼‰
python rag_vs_lc.py --method rag --limit 100 --k 9  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

# LC å›é€€åˆ° 12k å†å¯¹æ¯”ä¸€æ¬¡
python rag_vs_lc.py --method lc  --limit 100 --max_chars 12000 --temperature 0.0

```

![image-20250904104239167](../../AppData/Roaming/Typora/typora-user-images/image-20250904104239167.png)

- **RAGï¼ˆk=9ï¼Œbge-smallï¼‰**ï¼š**EM 0.39 / F1 0.53 / 1.78s**
- **LCï¼ˆ12kï¼‰**ï¼š**EM 0.34 / F1 0.486 / 1.67s**

ç»“è®ºï¼šåœ¨ä½ è¿™ä¸ªç«¯ç‚¹ä¸æ•°æ®é›†ä¸Šï¼Œ**RAG å·²åè¶… LC**ï¼ˆå‡†ç¡®æ›´é«˜ï¼Œå»¶è¿Ÿåªç•¥é«˜â‰ˆ110msï¼‰ã€‚å¯ä»¥æŠŠ RAG ä½œä¸ºå½“å‰é»˜è®¤æ–¹æ¡ˆã€‚

:hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs::hugs:

**æŠŠ RAG å†æ¦¨ä¸€ç‚¹ï¼ˆ+Rerankï¼‰**

ä¸¤æ®µæ”¹åŠ¨å³å¯ï¼ŒåŠ ä¸€ä¸ªäº¤å‰ç¼–ç å™¨åšäºŒæ®µæ’åºï¼Œé€šå¸¸ **+3ï½8 F1**ã€‚

```
åŸï¼š
class PerSampleRetriever:
    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.embedder = SentenceTransformer(model_name)

    def topk(self, passages: List[Tuple[str,str]], query: str, k: int=3):
        if len(passages) <= k:
            return passages
        texts = [p[1] for p in passages]
        # å½’ä¸€åŒ–åç”¨å†…ç§¯è¿‘ä¼¼ä½™å¼¦
        q_emb = self.embedder.encode([query], normalize_embeddings=True)
        p_emb = self.embedder.encode(texts, normalize_embeddings=True)
        index = faiss.IndexFlatIP(p_emb.shape[1])
        index.add(p_emb.astype("float32"))
        D, I = index.search(q_emb.astype("float32"), k)
        return [passages[i] for i in I[0].tolist()]
        
åï¼š
class PerSampleRetriever:
    def __init__(self, model_name="sentence-transformers/all-MiniLM-L6-v2",
                 rerank_model=None, rerank_topn=40):
        self.embedder = SentenceTransformer(model_name)
        self.ce = CrossEncoder(rerank_model) if rerank_model else None
        self.rerank_topn = rerank_topn

    def topk(self, passages, query, k=3):
        texts = [p[1] for p in passages]
        q = self.embedder.encode([query], normalize_embeddings=True)
        P = self.embedder.encode(texts, normalize_embeddings=True)

        import numpy as np, faiss
        index = faiss.IndexFlatIP(P.shape[1]); index.add(P.astype("float32"))
        topn = max(k, self.rerank_topn) if self.ce else k
        D, I = index.search(q.astype("float32"), topn)
        cand = [passages[i] for i in I[0].tolist()]

        if self.ce:  # äºŒæ®µrerankå†æŒ‘kä¸ª
            pairs = [(query, p) for _, p in cand]
            scores = self.ce.predict(pairs)  # è¶Šå¤§è¶Šç›¸å…³
            order = np.argsort(-scores)[:k]
            return [cand[i] for i in order]
        return cand[:k]

```

```
# RAG + bge-small + rerank
python rag_vs_lc.py --method rag --limit 100 --k 7 \
  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0
```

![image-20250904111858354](../../AppData/Roaming/Typora/typora-user-images/image-20250904111858354.png)

çœ‹åˆ°äº†ï¼Œè¿™æ¬¡ç”¨ **bge-small + k=7** ç»“æœæ‰åˆ°äº† *EM 0.23 / F1 0.35*ã€‚å¤§æ¦‚ç‡æ˜¯ **bge æ²¡ç”¨åˆ°ä¸“å±çš„ query/passsage æç¤º**ï¼›bge v1.5 éœ€è¦åœ¨ç¼–ç æ—¶åŠ ä¸Š `prompt_name='query'/'passage'`ï¼Œå¦åˆ™å¬å›ä¼šæ˜æ˜¾é€€æ­¥ã€‚

```
# ========== æ£€ç´¢å™¨ï¼ˆæ¯é¢˜åœ¨å…¶è‡ªå¸¦æ®µè½å†…æ£€ç´¢ï¼‰ ==========
class PerSampleRetriever:
    def __init__(self,
                 model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
                 rerank_model: str | None = None,
                 rerank_topn: int = 40):
        from sentence_transformers import SentenceTransformer
        self.model_name = model_name
        self.embedder = SentenceTransformer(model_name)
        self.rerank_topn = rerank_topn
        self.ce = None
        if rerank_model:
            try:
                from sentence_transformers import CrossEncoder
                self.ce = CrossEncoder(rerank_model)   # äºŒæ®µæ’åºæ¨¡å‹
            except Exception as e:
                print(f"[warn] load rerank model failed: {e}")
                self.ce = None

    def topk(self, passages: List[Tuple[str, str]], query: str, k: int = 3):
        if len(passages) <= k:
            return passages

        texts = [p[1] for p in passages]

        # ---- BGE v1.5 éœ€è¦ query/passsage çš„ prompt_nameï¼Œå¦åˆ™æ•ˆæœä¼šæ‰ ----
        use_bge = "bge" in self.model_name.lower()
        q_kw = {"normalize_embeddings": True}
        p_kw = {"normalize_embeddings": True}
        if use_bge:
            q_kw["prompt_name"] = "query"
            p_kw["prompt_name"] = "passage"

        q_emb = self.embedder.encode([query], **q_kw)
        p_emb = self.embedder.encode(texts, **p_kw)

        import faiss, numpy as np
        index = faiss.IndexFlatIP(p_emb.shape[1])
        index.add(p_emb.astype("float32"))

        topn = max(k, self.rerank_topn) if self.ce else k
        D, I = index.search(q_emb.astype("float32"), topn)
        cand = [passages[i] for i in I[0].tolist()]

        if self.ce:
            pairs = [(query, p) for _, p in cand]
            scores = self.ce.predict(pairs)  # åˆ†æ•°è¶Šå¤§è¶Šç›¸å…³
            order = np.argsort(-scores)[:k]
            return [cand[i] for i in order]

        return cand[:k]

```

```
# bge-small + æ­£ç¡® prompts
python rag_vs_lc.py --method rag --limit 100 --k 7 --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0
python rag_vs_lc.py --method rag --limit 100 --k 9 --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

```

![image-20250904114825503](../../AppData/Roaming/Typora/typora-user-images/image-20250904114825503.png)

ç¡®å®å˜å·®äº†ï¼Œè¯´æ˜æˆ‘ä»¬è¿™æ¬¡å¯¹ **BGE çš„ prompt ç”¨æ³•**æ²¡æ‰“å‡†ï¼ˆæˆ–ç‰ˆæœ¬ä¸ä¸€è‡´ï¼‰ã€‚

![image-20250904160606320](../../AppData/Roaming/Typora/typora-user-images/image-20250904160606320.png)

 **å¯¹ BGE åš AB æµ‹è¯•ï¼ˆå…³æ‰ prompt / è‡ªåŠ¨é€‰æ‹© promptï¼‰**

ç„¶åè·‘ä¸¤æ¬¡å¯¹ç…§ï¼š

```
# A: å…³é—­ BGE çš„ promptï¼ˆå¤ç°ä½ ä¹‹å‰çš„å¥½æˆç»©ï¼‰
BGE_PROMPTS=off \
python rag_vs_lc.py --method rag --limit 100 --k 9 \
  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

# B: å¼€å¯è‡ªåŠ¨ promptï¼ˆæˆ‘ä»¬åˆšæ”¹çš„è‡ªé€‚é…ï¼‰
python rag_vs_lc.py --method rag --limit 100 --k 9 \
  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

```

![image-20250904161702502](../../AppData/Roaming/Typora/typora-user-images/image-20250904161702502.png)

ä½ æ€€ç–‘å¯¹å¾—å¾ˆæœ‰é“ç†ã€‚å›é€€æ£€æŸ¥åï¼Œæˆ‘å‘ç°**çœŸæ­£çš„é—®é¢˜åœ¨äº BGE v1.5 çš„ç”¨æ³•**ï¼š
 å¯¹å¤§å¤šæ•° `bge-*-en-v1.5` æ¨¡å‹ï¼Œ**åªéœ€è¦åœ¨â€œæŸ¥è¯¢ä¾§â€åŠ  `prompt_name='query'`**ï¼›**æ–‡æ¡£ä¾§ä¸è¦åŠ ä»»ä½• prompt**ã€‚æˆ‘å‰é¢çš„ç‰ˆæœ¬ç»™æ–‡æ¡£ä¾§å¥—äº† `document/passage` çš„ promptï¼Œç¡®å®ä¼šæŠŠç›¸ä¼¼åº¦å­¦åˆ°çš„ç©ºé—´â€œæ‰­åâ€ï¼Œå¯¼è‡´å¬å›éª¤é™ï¼ˆä½ çœ‹åˆ°çš„ EM/F1 å¤§å¹…ä¸‹æ»‘å°±æ˜¯è¿™ä¸ªåŸå› ï¼‰ã€‚

ä¸‹é¢ç»™ä½ ä¸€ç‰ˆ**æœ€å°ä¸”ç¨³å¦¥**çš„æ£€ç´¢å™¨ï¼Œä¿æŒä½ åŸå§‹é€»è¾‘ä¸å˜ï¼Œåªåœ¨æ£€æµ‹åˆ° BGE æ—¶**å¯¹æŸ¥è¯¢ä¾§**åŠ ä¸Š `query` promptï¼›æ–‡æ¡£ä¾§ä¸åŠ¨ã€‚`rerank` ä»ç„¶æ˜¯å¯é€‰å¼€å…³ï¼Œä¸ä¼ å°±å’Œä½ æœ€åˆä¸€æ¨¡ä¸€æ ·ã€‚

```
# ========== æ£€ç´¢å™¨ï¼ˆæ¯é¢˜åœ¨å…¶è‡ªå¸¦æ®µè½å†…æ£€ç´¢ï¼‰ ==========
class PerSampleRetriever:
    def __init__(self,
                 model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
                 rerank_model: str | None = None,
                 rerank_topn: int = 40):
        from sentence_transformers import SentenceTransformer, CrossEncoder
        self.model_name = model_name
        self.embedder = SentenceTransformer(model_name)
        self.ce = CrossEncoder(rerank_model) if rerank_model else None
        self.rerank_topn = rerank_topn

    def topk(self, passages, query, k: int = 3):
        if len(passages) <= k:
            return passages

        texts = [p[1] for p in passages]

        # ---- åªå¯¹ BGE v1.x åœ¨â€œæŸ¥è¯¢ä¾§â€åŠ  query promptï¼›æ–‡æ¡£ä¾§ä¸åŠ  ----
        use_bge = "bge" in self.model_name.lower()
        q_kw = {"normalize_embeddings": True}
        p_kw = {"normalize_embeddings": True}
        if use_bge:
            prompts = getattr(self.embedder, "prompts", {}) or {}
            if "query" in prompts:
                q_kw["prompt_name"] = "query"   # âœ… åªåŠ è¿™ä¸€å¤„

        q_emb = self.embedder.encode([query], **q_kw)
        p_emb = self.embedder.encode(texts, **p_kw)

        import faiss, numpy as np
        index = faiss.IndexFlatIP(p_emb.shape[1])
        index.add(p_emb.astype("float32"))

        topn = max(k, self.rerank_topn) if self.ce else k
        D, I = index.search(q_emb.astype("float32"), topn)
        cand = [passages[i] for i in I[0].tolist()]

        if self.ce:
            scores = self.ce.predict([(query, p) for _, p in cand])
            order = np.argsort(-scores)[:k]
            return [cand[i] for i in order]
        return cand[:k]

```

```
# 1) bge-small + k=9ï¼ˆé¢„æœŸæ¢å¤åˆ°ä½ ä¹‹å‰çš„é«˜åˆ†åŒºé—´ï¼‰
python rag_vs_lc.py --method rag --limit 100 --k 9 \
  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

# 2) å¯é€‰ï¼šåœ¨ 1) çš„åŸºç¡€ä¸Šå¼€ rerankï¼ˆå¸¸è§ +3~8 F1ï¼‰
RERANK_MODEL="cross-encoder/ms-marco-MiniLM-L-6-v2" RERANK_TOPN=40 \
python rag_vs_lc.py --method rag --limit 100 --k 7 \
  --embedding "BAAI/bge-small-en-v1.5" --temperature 0.0

```

